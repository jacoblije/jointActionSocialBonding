%%%APPENDICES FOR CHAPTER 6 TRAINING EXPERIMENT
\chapter{\label{app6:trainingExperiment}Training Experiment Appendix}

\section{\label{app6:method}Method}

\subsection{\label{app6:difficultyPilot}Invasion Drill pilot for difficulty rating}
In order to gauge the difficulty rating of the Invasion Drill, 20 junior athletes from the Beijing provincial team (male = 10,  M(age) = 19) were recruited to participate in a pilot study designed to test the difficulty rating of the Invasion Drill. Two separate pilot sessions were conducted, one with the men and another with the women. Following a routine warm-up procedure not involving a rugby ball (~10 minutes), athletes in each session completed 28 rounds of the Invasion Drill.  Given that the drill required only 8 athletes, all 10 athletes rotated through two extra ``resting'' positions on the sideline of the drill.  The invasion drill was also flanked on either side with two other  training drills, a more simple ``2 on 1 + 1'' attacking drill and a more complex ``6 on 4 continuous'' attacking drill.  Athletes not participating in the 2 on 1+1 drill rested on the sideline and rotated in after each trial.  All ten athletes were engaged in the 6 on 4 continuous drill. At the end of the training session, athletes were asked to record the perceived difficulty of each training drill from the pilot session using a ten-point scale (0 - ``Extremely easy'', 5 - ``Average'', 10 - ``Extremely difficult''). These results were collected and collated by the researcher.

On average, athletes rated the invasion drill at 4.7/10 (range = 3 to 7).  The more simple ``2 on 1+1'' attacking drill received an average rating of 2 (range = 1-4), and the more complex ``6 on 4 continuous'' attacking drill received an average rating of 6.2 (range = 4-10). Ratings of perceived difficulty did not significantly vary by pilot group (i.e., sex). This pilot study confirmed that it was appropriate to estimate the actual difficulty rating of the invasion drill at approximately 5/10, meaning that the high difficulty manipulation (8/10) and the low difficulty rating (2/10) could fall evenly at either side of this difficulty.


\subsection{\label{app6:conditionPrime}Experiment condition primes}

\subsubsection{\label{app6:conditionPrimeHigh}High difficulty condition}
The drill you will be participating in today is a ``4 on 2 + 2'' drill taken from World Rugby.  This drill, also known as ``Invasion Drill'' involves four attackers and two phases of two defenders in a 15m x 22m channel.  The other group will be participating in a different type of drill.  International coaches have assessed this drill based on a number of different factors (including drill complexity, coordination, intensity, skill requirement, etc.), and a sample of professional rugby players from all over the world, including China, have rated this drill based on its difficulty.  World Rugby has combined these two measures and concluded that it is a very difficult drill for players to perform together successfully.  This drill was given a score of 77.5/100, which translates to a difficulty rating of about 8/10.  So the requirements of this drill—in coordinating both attack and defence—are quite high.

\subsubsection{\label{app6:conditionPrimeLow}Low difficulty condition}
The drill you will be participating in today is a ``4 on 2 + 2'' drill taken from World Rugby.  This drill, also known as ``Invasion Drill'' involves four attackers and two phases of two defenders in a 15m x 22m channel.  The other group will be participating in a different type of drill.  International coaches have assessed this drill based on a number of different factors (including drill complexity, coordination, intensity, skill requirement, etc.), and a sample of professional rugby players from all over the world, including China, have rated this drill based on its difficulty.  World Rugby has combined both of these measures and concluded that it is a very easy drill for players to perform together successfully.  This drill was given a score of 22.5/100, which translates to a difficulty rating of about 2/10.  So the requirements of this drill—in coordinating both attack and defence—are quite low.

\subsection{\label{app6:drillExplanation}Drill explanation (constant across both conditions)}
The drill will work as follows:  when I blow the whistle, the first group of four attackers will assemble on the diamond pattern of four cones and prepare to attack, while two lines of two defenders each will assemble on the assigned cones, 10m apart from each other.  When I blow the whistle a second time, the ball carrier at the top of the attacking diamond will tap the ball on his/her foot and proceed to engage the attack in a 4on2 scenario.  The goal of the attacking group is to penetrate both lines of defence without being held by the defenders.  After participating in the first line of defence, the first two defenders must stay put, and cannot follow the play and participate in the second line of defence.

Defenders can “hold/hug” attackers in order to hold the attack, but the drill is not a full-contact drill.  Attackers can offload the ball at the first opportunity after making contact with a defender, if they are not fully held by the defenders.  If the attacker does not unload the ball immediately, then the play is dead and the drill will be reset.
After every phase I will ask athletes to rotate clockwise around the drill, such that the ball carrier at the top of the diamond goes on to become a defender on the top right side of the square of defenders. Each individual athlete should attack a total of 8 rounds, and defend a total of 8 rounds, performing every position in the drill twice.

The drill will be recorded using a digital video camera, and individual athletes will be assessed based on their performance in attack and defence, using special video analysis software. I am particularly interested in how well players are able to coordinate with others in attack and defence.





\subsection{\label{app6:surveyItems}Survey items}



\subsubsection{\label{app6:surveyItemsBaseline}Baseline}

\myparagraph{\label{app6:surveyItemsBaselinePerformance}Perceptions of recent performance}
Survey items relating to performance included questions regarding athlete feelings about their 1) overall individual performance, 2) specific components of individual performance (passing technique, support play in attack, 1on1 defence, effectiveness in contact, and decision making in game-play), 3) overall team performance, and 4) specific components of team performance (coordination of the defensive line and attacking line, support play, and on-field communication) throughout the past month of training and competition.  All these items were recorded on a 100 point scale, 0 - ``Extremely poor'', 100 - ``Extremely good.''

\myparagraph{\label{app6:surveyItemsBaselineClick}Team Click}
Athletes were asked about their feelings concerning team click among the entire provincial squad over the past month.  These items included: feelings about the unspoken understanding between athletes, the general atmosphere of the team (100 point scale, 0 - ``Extremely poor'', 100 - ``Extremely strong''), the extent to which they agree that their on-field abilities have been extended by other athletes (100 point scale, 0 - ``Completely disagree'', 100 - ``Completely agree''), and the reliability of other athletes to perform on-field roles and their own reliability in performing on-field roles for other athletes (100 point scale, 0 - ``Extremely unreliable'', 100 - ``Extremely reliable''), and a pictorial ``team click" measure (a visual item with five responses, ranging from less to more coordinated arrangements of dots (representing 12 athletes in a sevens tournament squad).

\myparagraph{\label{app6:surveyItemsBaselineBonding}Social Bonding}
Athletes were asked about their feelings of social bonding to their team over the past month, including perceived emotional support and shared goal (100 point scale, 0 - ``Exrtremely weak'', 100 - ``Extremely strong''), identity fusion (pictorial scale and 7 item verbal scale, see APPENDIX), and group identification (six-item scale, see APPENDIX). In addition, athletes were also asked about identity fusion to country and family, measured using the pictorial fusion scale, and were then asked to rank their level of fusion to team, country, and family in order of most fused to least fused.


\myparagraph{\label{app6:surveyItemsBaselineCompetence}Technical Competence}
Athletes were asked about their individual technical competence: ``Rate your individual ability in rugby, relative to: 1) Other teammates currently in your team, 2) Other current professional Chinese rugby players, 3) Professional rugby players form other countries.'' (Items were measured with a zero-centred 100 point scale, -50 - ``Extremely weak'', 0 - ``Average'', 50 - ``Extremely strong'').  Athletes were also asked about perceived competence of their team relative to other Chinese provincial teams: ``Rate your team's overall ability, relative to other teams in China'' (100 point scale, -50 - ``Extremely weak'', 0 - ``Average'', 50 - ``Extremely strong'').  In addition, athletes were asked if their perception of recent performance influences their 1) mood and 2) confidence regarding future performance (All these items were measured with a zero-centred 100 point scale, -50 - ``Extremely weak'', 0 - ``Average'', 50 - ``Extremely strong'').

Athletes were asked to report rugby-related attributes that would provide a more objective indicator of technical competence. These measures included: 1) rugby training age (number of years of experience training for rugby, to the nearest number of years), 2) the number of years spent training with the provincial teams (to the nearest year), 3) athlete status (Master Athlete, First Level Athlete, Second Level Athlete)\footnote{Explain athlete status accreditation}, 4) contract level with the provincial team (permanent employee of the provincial sport institute, full time contract, training contract, student contract, trial contract), 5) whether the athlete is a usual member of the provincial program's starting team or the reserves.


\myparagraph{\label{app6:TIPI}Ten Item Personality Index}
Athletes were asked to indicate on a 7-point Likert scale the extent to which they agreed with 10 pairs of adjectives as appropriate descriptions of their personality. For example: ``I see myself as: dependable, self-disciplined'' (Response: 1 - ``Disagree strongly'', 2 - ``Disagree moderately'',  3 - ``Disagree a little'', 4 - ``Neither agree nor disagree'', 5 - ``Agree a little'', 6 - ``Agree moderately'', 7 - ``Agree strongly''). In the TIPI, two survey items corresponded to each of the big-five personality types, as follows:

\begin{description}
\item [Extraversion:] 1. Extraverted, enthusiastic; 6. Reserved, quiet (Reversed scale)
\item [Agreeableness:] 2. Critical, quarrelsome (Reversed); 7. Sympathetic, warm
\item [Conscientiousness:] 3. Dependable, self-disciplined; 8. Disorganised, careless (Reversed)
\item [Emotional Stability:] 4. Anxious, easily upset (Reversed); 9. Calm, emotionally stable.
\item [Openness to Experiences:] 5. Open to new experiences, complex; 10.Conventional, uncreative (Reversed)
\end{description}


\myparagraph{\label{app6:surveyItemsBaselineAdditional}Additional Items}
Athletes were asked about their feelings regarding their team's commitment to aspects of team discipline over the past month (punctuality to training and team meetings, observing bed times and curfews, attendance at meals, general team conduct) (100 point scale for each item, 0 - ``Extremely poor'', 100 - ``Extremely strong'')).

NAME
DOB
PLAYING POSITION
INJURY



\subsubsection{\label{app6:surveyItemsPre}Pre-Experiment Survey Items}
Survey items administered at time 2, following the experimental manipulation and immediately prior to the experiment, were designed to measure athletes' expectations regarding individual and group performance in light of the experimental prime. It also included items designed to measure athletes' perceptions of team click and social bonding to the training group (but not the team as a whole beyond the immediate training group).
In addition to these items, the time 2 survey also asked about current injury status, and state of arousal and fatigue








\subsubsection{\label{app6:surveyItemsPost}Post-Experiment Surveys}
The final survey, administered at time 3 immediately post-experiment, consisted of items designed to assess athlete perceptions of individual and group performance in the experiment relative to prior expectations, as well as feelings of team click and social bonding to the training group. In addition to items already described above, athletes were asked if they would prefer to stay with their existing group or change to a new group for subsequent training experiments.  In addition to these group-specific items, the time 3 survey also included items regarding social bonding to the team as a whole (beyond an athlete's specific training group), in order to assess any change in these measures due to their experience of joint action in the experiment.  Finally, the time 3 survey also asked about current injury status and state of arousal and fatigue (see APPENDIX for full details).



\item [Identity Fusion Pictorial] A visual scale designed to measure Identity Fusion to the target in-group \citep{Swann2009}. The pictorial scale depicts two circles, one smaller circle to denote the individual, and one larger circle to denote the group, progressively moving closer to each other such that the most ``fused'' option depicts the smaller circle encased by the larger circle. The scale offers a total of five options to chose from, see Figure ~\ref{fig:fusionPictorialGroup}.  A total of three pictorial scales were included, each with different target in-groups: team, family, and country (China).
\item [Fusion Pictorial Rank] Athletes were asked to rank their fusion to team, family, and country \citep{Whitehouse2014}.  ``Thinking about these relationships [to team, family, and country] please rank them below in order of which you feel most connected to. 1 for most connected, 3 for least connected.''
\end{description}

\item [Identity Fusion Verbal] A seven-item scale designed to measure an individual's ``feeling of oneness with the group'' \citep{Swann2009}.  Identity Fusion is differentiated from Group Identification in its ability to account for an individual's felt, emotional and personal agentic associations with being a member of the target in-group \citep{Swann2012a}.  All 7 items were measured using a 5-point Likert scale.


\item [Emotional Support] ``How emotionally supportive does the team feel?''
\item [Shared Goal] ``How strong is the feeling that everyone is working towards a shared goal?''

\item [Group Identification Verbal] A six-item scale designed to measure an individual's personal identification with the stereotypical features of the in-group  \citep{Mael1992}.  All 6 items were measured using a 5-point Likert scale.

%1. When someone critizes my team, it feels like a personal insult
%2. I am very interested in what others think about my team
%3. When I talk about my team, I usually say “we” rather than “they"
%4. This team's successes are my successes
%5. When someone praises my team, it feels like a personal compliment
%6. If a story in the media criticized my team, I would feel embarrassed







\section{\label{app6:results}Results}


\input{.../images/compPerfSubjTraining.tex}
%%IndPerforamnce:
\input{.../images/indPerfTimeLowTraining.tex}
\input{.../images/indPerfTimeHighTraining.tex}
%% groupPerformance:
\input{.../images/groupPerfTimeLowTraining.tex}
\input{.../images/groupPerfTimeHighTraining.tex}
%% teamPerformance:
\input{.../images/teamPerfTimeBaselineTraining.tex}
%% groupClick:
\input{.../images/groupClickTimeHighTraining.tex}
\input{.../images/groupClickTimeLowTraining.tex}
%% groupBonding:
\input{.../images/groupBondingTimeHighTraining.tex}
\input{.../images/groupBondingTimeLowTraining.tex}
%% teamBonding:
\input{.../images/teamBondingTimeLowTraining.tex}
\input{.../images/teamBondingTimeHighTraining.tex}


%% Objective Performance:
%\input{.../images/objectiveOutcomeCondition.tex
%%teamDiscipline
%\input{.../images/teamDisciplineTimeLowTraining.tex}
%%ArousalExertion:
%\input{...images/arousalExertionTimeLowTraining.tex}
%%Personality:
%\input{.../images/personalityTraining.tex}


\subsubsection{Moderator Variables}

The central tendencies of subjective measures of individual technical competence compared to teammates, other Chinese professional rugby players, and International professionals, were all above the mid-point of the zero-centred scale (min = -50, max = 50), with average scores ranging from  a low of 14.11 (SD = 26.88) for perceived technical competence relative to International professionals recorded at Baseline in the low difficulty condition (100 point zero-centred scale, min = -50, max = 50), to a high of 25.41 (15.49) for perceived technical competence relative to teammates, recorded at Baseline in the high-difficulty condition (see Appendix Table ~\ref{tab:compPerfSubjTraining} for details).  The central tendencies for items concerning the impact of individual performance on mood and confidence were also well above the mid-point of the scale, beetween 66-70 (SD range = 15.49 to 26.88) (100 point scale, min = 0, max = 100).




<<descriptivesPreFactor, echo = FALSE, eval = TRUE>>=
low <- subset(twc, condition == "low")
high <- subset(twc, condition == "high")
##subset data for renaming
twcAthleteInfo <- subset(twc, select = c(age, sex, condition, team, startingReserve,
                                    trainingAge, yearsTeam, athleteStatus, teamStatus))

## rename values for factors:
twcAthleteInfo$sex <- ifelse(!is.na(twcAthleteInfo$sex) & twcAthleteInfo$sex == 0, "male",
                                    ifelse(!is.na(twcAthleteInfo$sex) & twcAthleteInfo$sex == 1, "female", NA))


twcAthleteInfo$athleteStatus <- ifelse(!is.na(twcAthleteInfo$athleteStatus) &
                                    twcAthleteInfo$athleteStatus == 3, "Master",
                                      ifelse(!is.na(twcAthleteInfo$athleteStatus) & twcAthleteInfo$athleteStatus == 2, "1st Level",
                                        ifelse(!is.na(twcAthleteInfo$athleteStatus) & twcAthleteInfo$athleteStatus == 1, "2nd Level", NA)))

twcAthleteInfo$teamStatus <- ifelse(!is.na(twcAthleteInfo$teamStatus) &
                                    twcAthleteInfo$teamStatus == 5, "Full time employee",
                                      ifelse(!is.na(twcAthleteInfo$teamStatus) & twcAthleteInfo$teamStatus == 4, "Full time contract",
                                        ifelse(!is.na(twcAthleteInfo$teamStatus) & twcAthleteInfo$teamStatus == 3, "Training contract",
                                        ifelse(!is.na(twcAthleteInfo$teamStatus) & twcAthleteInfo$teamStatus == 2, "Student contract",
                                        ifelse(!is.na(twcAthleteInfo$teamStatus) & twcAthleteInfo$teamStatus == 1, "Trial",
                                         NA)))))

twcAthleteInfo$team <- ifelse(!is.na(twcAthleteInfo$team) & twcAthleteInfo$team ==
                                        "bjm","Beijing Men", ifelse(!is.na(twcAthleteInfo$team) & twcAthleteInfo$team == "bjw", "Beijing Women", ifelse(!is.na(twcAthleteInfo$team) & twcAthleteInfo$team == "sdm", "Shandong Men", ifelse(!is.na(twcAthleteInfo$team) & twcAthleteInfo$team == "sdw", "Shandong Women", NA))))

##rename columns for tables:
twcAthleteInfo <- rename(twcAthleteInfo, Position = startingReserve,
                              TrainingAge = trainingAge, YearsInTeam = yearsTeam, AthleteLevel = athleteStatus, ContractStatus = teamStatus, Team = team, Condition = condition, Sex = sex, Age = age)


## create a variable list which we want in table one
listVars <- c("Age", "Sex", "Team", "Position",  "TrainingAge" , "YearsInTeam", "AthleteLevel", "ContractStatus")

## define categorical variables
catVars <- c("Sex", "Condition", "AthleteLevel", "Position", "ContractStatus", "Team")


## Create overall table:
table1 <- CreateTableOne(vars = listVars,
                         data = twcAthleteInfo,
                         factorVars = catVars,
                         test = F
                         )

## create table which is printable
table1_overall <- print(table1,
                            quote = FALSE,
                            noSpaces = FALSE,
                            printToggle = FALSE
                            )

## print to latex file in wd
## this latex file will later be inputted
print(xtable(table1_overall, type="latex", caption = "Overview of experiment sample",
                    label = "tab:athleteDescriptivesTraining"),
                    file="athleteDescriptivesTraining.tex")

## create table one, strata = Condition
table1 <- CreateTableOne(vars = listVars,
                         strata = "Condition",
                         data = twcAthleteInfo,
                         factorVars = catVars,
                         test = F
                         )

## create table which is printable
table1_overall <- print(table1,
                            quote = FALSE,
                            noSpaces = FALSE,
                            printToggle = FALSE
                            )

## print to latex file in wd
## this latex file will later be inputted
print(xtable(table1_overall, type="latex",
                              caption = "Overview of experiment sample by condition",
                              label = "tab:athleteDescriptivesConditionTraining"),
                              file="athleteDescriptivesConditionTraining.tex")
@




MANIPULATION CHECKS:

\input{/Users/jacob1/Documents/2017/Research/DPhil/Dissertation/finalDocuments/jointActionSocialBonding/images/clickBondConditionPost.tex}

\input{/Users/jacob1/Documents/2017/Research/DPhil/Dissertation/finalDocuments/jointActionSocialBonding/images/factorsTimeHigh.tex}
\input{/Users/jacob1/Documents/2017/Research/DPhil/Dissertation/finalDocuments/jointActionSocialBonding/images/factorsTimeLow.tex}
\input{/Users/jacob1/Documents/2017/Research/DPhil/Dissertation/finalDocuments/jointActionSocialBonding/images/factorsCondition.tex}



DATA REDUCTION:

%team click
% "teamClickPictorial_1"  # TEAM CLICK post not measured
% [94] "reliabilityForOthers_1" # TEAM RELIABILITY - i don't ask about the team as a whole post-experiment...
% [95] "reliabilityOfOthers_1"


\myparagraph{Perceptions of Training Group Joint Action Success}
<<dataReductionGroupPerformance, echo=F,eval=T>>=
    #groupPerformanceVariablesSubset:
    tlcGroupPerformance <- subset(tlc, select = c(groupDefensiveLine, groupAttackingLine,
                                                      groupSupportPlay, groupOnfieldCommunication))
    tlcGroupPerformance.pca <- princomp(na.omit(tlcGroupPerformance))
    summary(tlcGroupPerformance.pca)
    plot(tlcGroupPerformance.pca)

    tlcGroupPerformance.fa <- factanal(~ groupDefensiveLine + groupAttackingLine +
                                                groupSupportPlay + groupOnfieldCommunication, 1, data = tlc, rotation = "promax", na.action = na.exclude, scores = "regression")  #<- this formula format allows preserving of NAs for later rebind to df

    #-----------------------------SS Loadings----------------------#
    SSLoadings.groupPerformanceFA <- round(sum(tlcGroupPerformance.fa$loadings[,1]^2), digits = 2)
    #------------------Proportion of Variance----------------------#
    prVar.GroupPerformanceFA <-  round((colSums(tlcGroupPerformance.fa$loadings*tlcGroupPerformance.fa$loadings)/dim(tlcGroupPerformance.fa$loadings)[1]*100), digits = 1)


    head(tlcGroupPerformance.fa$scores)
    tlc <- cbind(tlc, tlcGroupPerformance.fa$scores)
    names(tlc)[names(tlc) == "Factor1"] <- "jointActionSuccess"
    groupPerformanceMatrix <- cor(tlcGroupPerformance, use = "complete")

    #---------suitability measures (KMO & Bartlett)----------------#
    library(psych)
    KMOgroupPerformanceMatrix <- KMO(groupPerformanceMatrix)
    # KMOGroupPerformanceMatrix$MSA is the colum in which the overal KMO is stored
    bartlettGroupPerformance <- cortest.bartlett(groupPerformanceMatrix, n = 116) # what is the sample size here?
    # ls(BartlettGroupPerformance)
    # BartlettGroupPerformance$chisq, BartlettGroupPerformance$df, BartlettGroupPerformance$p.value
    # sample size? length(unique(tlc$englishName)*2)
    groupPerformanceSampleSize <- length(unique(tlc$englishName))*2 # values for each participant measured attwo time points

    #----------reliability measures--------------------------------#
    # Cronbach's Alpha and Guttman's Lambda using psych::alpha()
    #Cronbach's Alpha is located reliabilityObject$total[,2]
    #Guttman's Lambda is located reliabilityObject$total[,3]
    reliabilityGroupPerformance <- psych::alpha(groupPerformanceMatrix)
    cronAlphaGroupPerformance <- reliabilityGroupPerformance$total[,2]
    guttLambdaGroupPerformance <- reliabilityGroupPerformance$total[,3]


    #-----------------------Correlation Table----------------------#
    library(xtable)
    corstarsl <- function(x){
      require(Hmisc)
      x <- as.matrix(x)
      R <- rcorr(x)$r
      p <- rcorr(x)$P

      ## define notions for significance levels; spacing is important.
      mystars <- ifelse(p < .001, "***", ifelse(p < .01, "** ", ifelse(p < .05, "* ", " ")))
      ## trunctuate the matrix that holds the correlations to two decimal
      R <- format(round(cbind(rep(-1.11, ncol(x)), R), 2))[,-1]
      ## build a new matrix that includes the correlations with their apropriate stars
      Rnew <- matrix(paste(R, mystars, sep=""), ncol=ncol(x))
      diag(Rnew) <- paste(diag(R), " ", sep="")
      rownames(Rnew) <- colnames(x)
      colnames(Rnew) <- paste(colnames(x), "", sep="")
      ## remove upper triangle
      Rnew <- as.matrix(Rnew)
      Rnew[upper.tri(Rnew, diag = TRUE)] <- ""
      Rnew <- as.data.frame(Rnew)
      ## remove last column and return the matrix (which is now a data frame)
      Rnew <- cbind(Rnew[1:length(Rnew)-1])
      return(Rnew)
    }
@

<<groupPerformanceCor, echo=F,eval=T>>=
  # be sure to import the variable subset data frame, not the correlation matrix
  corstarsl(tlcGroupPerformance)
  print(xtable(corstarsl(tlcGroupPerformance), type="latex",
                      caption = "Correlations between components of group performance",
                      label = "tab:jointActionSuccessCorrTable"),
                      file = "jointActionSuccessCorrTable.tex")
@

Items concerning components of group performance in the invasion drill (defence, attack, support play, and on field communication) were subjected to EFA.
Correlations between group component performance items was very high (all r's > \Sexpr{min(groupPerformanceMatrix)}), which suggested that one factor was appropriate (see Appendix Table ~\ref{tab:jointActionSuccessCorrTable}).
The KMO index and Bartlett's test both suggested high sampling adequacy, (KMO =  \Sexpr{KMOgroupPerformanceMatrix$MSA}, \chi^2(\Sexpr{bartlettGroupPerformance$df}, N = \Sexpr{groupPerformanceSampleSize}) = \Sexpr{bartlettGroupPerformance$chisq}, p = \Sexpr{bartlettGroupPerformance$p.value}. One factor, labelled ``Joint Action Success'' was imposed on the data, which explained \Sexpr{prVar.GroupPerformanceFA}\% of the overall variance (SS Loading = \Sexpr{SSLoadings.groupPerformanceFA}).
Guttmans \lambda = \Sexpr{reliabilityGroupPerformance$total[,3]} and Cronbachs \alpha = \Sexpr{(reliabilityGroupPerformance$total[,2]} indicated that the data reduction was appropriate and reliable.


\myparagraph{Perceptions of Individual Component Performance}
<<dataReductionIndPerformance, echo=F,eval=T>>=
    #indPerformanceVariablesSubset: exclude effectivenessInContact (not relevant)
    tlcIndPerformance <- subset(tlc, select = c(indDefense, passingTechnique, supportPlay,
                                                      decisionMaking))
    tlcIndPerformance.pca <- princomp(na.omit(tlcIndPerformance))
    summary(tlcIndPerformance.pca)
    plot(tlcIndPerformance.pca)

    tlcIndPerformance.fa <- factanal(~ indDefense + passingTechnique + supportPlay +
                                            decisionMaking, 1, data = tlc, rotation = "promax",
                                            na.action = na.exclude, scores = "regression")
    #<- this formula format allows preserving of NAs for later rebind to df

    #-----------------------------SS Loadings----------------------#
    SSLoadings.indPerformanceFA <- round(sum(tlcIndPerformance.fa$loadings[,1]^2), digits = 2)
    #------------------Proportion of Variance----------------------#
    prVar.indPerformanceFA <-  round((colSums(tlcIndPerformance.fa$loadings*tlcIndPerformance.fa$loadings)/dim(tlcIndPerformance.fa$loadings)[1]*100), digits = 1)


    head(tlcIndPerformance.fa$scores)
    tlc <- cbind(tlc, tlcIndPerformance.fa$scores)
    names(tlc)[names(tlc) == "Factor1"] <- "indComponentsPerformance"
    indPerformanceMatrix <- cor(tlcIndPerformance, use = "complete")

    #---------suitability measures (KMO & Bartlett)----------------#
    library(psych)
    KMOindPerformanceMatrix <- KMO(indPerformanceMatrix)
    # KMOIndPerformanceMatrix$MSA is the colum in which the overal KMO is stored
    bartlettIndPerformance <- cortest.bartlett(indPerformanceMatrix, n = 116) # what is the sample size here?
    # ls(BartlettIndPerformance)
    # BartlettIndPerformance$chisq, BartlettIndPerformance$df, BartlettIndPerformance$p.value
    # sample size? length(unique(tlc$englishName)*2)
    indPerformanceSampleSize <- length(unique(tlc$englishName))*2 # values for each participant measured attwo time points

    #----------reliability measures--------------------------------#
    # Cronbach's Alpha and Guttman's Lambda using psych::alpha()
    #Cronbach's Alpha is located reliabilityObject$total[,2]
    #Guttman's Lambda is located reliabilityObject$total[,3]
    reliabilityIndPerformance <- psych::alpha(indPerformanceMatrix)
    cronAlphaIndPerformance <- reliabilityIndPerformance$total[,2]
    guttLambdaIndPerformance <- reliabilityIndPerformance$total[,3]
@

Items concerning components of individual components of performance in the invasion drill (1-on-1 defence, passing technique, support play in attack, decision making in attack, and effectiveness in contact) were subjected to EFA.  The variable ``effectiveness in contact'' was removed from analysis as the invasion drill was predominantly a non-contact training drill, and so this item was not relevant to athletes' performance.  Correlations between individual component performance items was very high (all r's > \Sexpr{min(indPerformanceMatrix)}), which suggested that one factor was appropriate (see Table ~\ref{tab:indComponentPerfCorrTable}).
The KMO index and Bartlett's test both suggested high sampling adequacy, (KMO =  \Sexpr{(KMOindPerformanceMatrix$MSA}, \chi^2(\Sexpr{bartlettIndPerformance$df}, N = \Sexpr{indPerformanceSampleSize}) = \Sexpr{bartlettIndPerformance$chisq}, p = \Sexpr{bartlettIndPerformance$p.value}. One factor, labelled ``Individual Performance Components'' was imposed on the data, which explained \Sexpr{prVar.indPerformanceFA} \% of the overall variance (SS Loading = \Sexpr{SSLoadings.indPerformanceFA}).  Guttmans \lambda = \Sexpr{reliabilityIndPerformance$total[,3]}  and  Cronbachs \alpha = \Sexpr{reliabilityIndPerformance$total[,2]}  indicated that the data reduction was appropriate and reliable.

<<indComponentsPerformanceCor, echo=F,eval=T>>=
  # be sure to import the variable subset data frame, not the correlation matrix
  corstarsl(tlcIndPerformance)
  print(xtable(corstarsl(tlcIndPerformance), type="latex",
                      caption = "Correlations between components of individual performance",
                      label = "tab:indComponentPerfCorrTable"),
                      file = "indComponengtPerfCorrTable.tex")
  # label = tab:indComponentPerformanceCorrTable
@







\subsubsection{Social Bonding to the team}

<<dataReductionTeamBonding, eval=TRUE, echo=FALSE>>=
  #TeamBondingVariablesSubset: exclude effectivenessInContact (not relvant)
  tlcTeamBonding <- subset(tlc, select = c(emotionalSupport, sharedGoal,
                                                fusionPictorialTeam, fusionVerbal, groupId))
  tlcTeamBonding.pca <- princomp(na.omit(tlcTeamBonding))
  summary(tlcTeamBonding.pca)
  #plot(tlcTeamBonding.pca)

  tlcTeamBonding.fa <- factanal(~ emotionalSupport + sharedGoal +
                                        fusionPictorialTeam + fusionVerbal + groupId, 1, data = tlc, rotation = "promax", na.action = na.exclude, scores = "regression")  #<- this formula format allows preserving of NAs for later rebind to df

  #-----------------------------SS Loadings----------------------#
  SSLoadings.teamBondingFA <- round(sum(tlcTeamBonding.fa$loadings[,1]^2), digits = 2)
  #------------------Proportion of Variance----------------------#
  prVar.teamBondingFA <-  round((colSums(tlcTeamBonding.fa$loadings*tlcTeamBonding.fa$loadings)/dim(tlcTeamBonding.fa$loadings)[1]*100), digits = 1)

  head(tlcTeamBonding.fa$scores)
  tlc <- cbind(tlc, tlcTeamBonding.fa$scores)
  names(tlc)[names(tlc) == "Factor1"] <- "teamBondingFactor"
  teamBondingMatrix <- cor(tlcTeamBonding, use = "complete")

  #---------suitability measures (KMO & Bartlett)----------------#
  library(psych)
  KMOteamBondingMatrix <- KMO(teamBondingMatrix)
  # KMOTeamBondingMatrix$MSA is the colum in which the overal KMO is stored
  bartlettTeamBonding <- cortest.bartlett(teamBondingMatrix, n = 116) # what is the sample size here?
  # ls(BartlettTeamBonding)
  # BartlettTeamBonding$chisq, BartlettTeamBonding$df, BartlettTeamBonding$p.value
  # sample size? length(unique(tlc$englishName)*2)
  teamBondingSampleSize <- length(unique(tlc$englishName))*2 # values for each participant measured attwo time points

  #----------reliability measures--------------------------------#
  # Cronbach's Alpha and Guttman's Lambda using psych::alpha()
  #Cronbach's Alpha is located reliabilityObject$total[,2]
  #Guttman's Lambda is located reliabilityObject$total[,3]
  reliabilityTeamBonding <- psych::alpha(teamBondingMatrix)
  cronAlphaTeamBonding <- reliabilityTeamBonding$total[,2]
  guttLambdaTeamBonding <- reliabilityTeamBonding$total[,3]
@
<<teamBondingCor, echo=F,eval=T>>=
  # be sure to import the variable subset data frame, not the correlation matrix
  corstarsl(tlcTeamBonding)
  print(xtable(corstarsl(tlcTeamBonding), type="latex",
                      caption = "Correlations between team bonding variables",
                      label = "tab:teamBondingCorrTable"),
                      file = "teamBondingCorrTable.tex")
  # label = tab:teamBondingCorrTable
@

Items concerning bonding to the team (emotional support, shared goal, fusion pictorial, fusion verbal, and group identification) were subjected to EFA.  Correlations between items were all reasonably high (all r's > \Sexpr{min(teamBondingMatrix)}), which suggested that one factor would be appropriate (see Table ee Table ~\ref{tab:teamBondingCorrTable}).
The KMO index and Bartlett's test both suggested high sampling adequacy, (KMO =  \Sexpr{KMOteamBondingMatrix$MSA}, \chi^2(\Sexpr{bartlettTeamBonding$df}, N = \Sexpr{teamBondingSampleSize}) = \Sexpr{bartlettTeamBonding$chisq}, p = \Sexpr{bartlettTeamBonding$p.value}).
One factor, labelled ``Team Social Bonding'' was imposed on the data, which explained \Sexpr{prVar.teamBondingFA} \% of the overall variance (SS Loading = \Sexpr{SSLoadings.teamBondingFA}). Guttmans \lambda = \Sexpr{reliabilityTeamBonding$total[,3]} and Cronbachs \alpha = \Sexpr{reliabilityTeamBonding$total[,2]} indicated that the data reduction was appropriate and reliable.

\myparagraph{Arousal}
<<dataReductionArousal, echo=F,eval=T>>=
  #ArousalVariablesSubset: exclude effectivenessInContact (not relvant)
  tlcArousal <- subset(tlc, select = c(aroused, relaxed, excited))
  tlcArousal.pca <- princomp(na.omit(tlcArousal))
  summary(tlcArousal.pca)
  #plot(tlcArousal.pca)

  tlcArousal.fa <- factanal(~ aroused + relaxed + excited, 1, data = tlc, rotation =        "promax", na.action = na.exclude, scores = "regression")  #<- this formula format allows preserving of NAs for later rebind to df

  #-----------------------------SS Loadings----------------------#
  SSLoadings.ArousalFA <- round(sum(tlcArousal.fa$loadings[,1]^2), digits = 2)
  #------------------Proportion of Variance----------------------#
  prVar.ArousalFA <-  round((colSums(tlcArousal.fa$loadings*tlcArousal.fa$loadings)/dim(tlcArousal.fa$loadings)[1]*100), digits = 1)

  head(tlcArousal.fa$scores)
  tlc <- cbind(tlc, tlcArousal.fa$scores)
  names(tlc)[names(tlc) == "Factor1"] <- "arousalFactor"
  arousalMatrix <- cor(tlcArousal, use = "complete")

  #---------suitability measures (KMO & Bartlett)----------------#
  library(psych)
  KMOarousalMatrix <- KMO(arousalMatrix)
  # KMOarousalMatrix$MSA is the colum in which the overal KMO is stored
  bartlettArousal <- cortest.bartlett(arousalMatrix, n = 116) # what is the sample size here?
  # ls(BartlettArousal)
  # BartlettArousal$chisq, BartlettArousal$df, BartlettArousal$p.value
  # sample size? length(unique(tlc$englishName)*2)
  arousalSampleSize <- length(unique(tlc$englishName))*2 # values for each participant measured attwo time points

  #----------reliability measures--------------------------------#
  # Cronbach's Alpha and Guttman's Lambda using psych::alpha()
  #Cronbach's Alpha is located reliabilityObject$total[,2]
  #Guttman's Lambda is located reliabilityObject$total[,3]
  reliabilityArousal <- psych::alpha(arousalMatrix)
  cronAlphaArousal <- reliabilityArousal$total[,2]
  guttLambdaArousal <- reliabilityArousal$total[,3]
@
<<arousalCor, echo=F,eval=T>>=
  # be sure to import the variable subset data frame, not the correlation matrix
  corstarsl(tlcArousal)
  print(xtable(corstarsl(tlcArousal), type="latex",
                      caption = "Correlations between variables measuring arousal",
                      label = "tab:arousalCorrTable"),
                      file = "arousalCorrTable.tex")
  # label = tab:arousalCorrTable
@

Items associated with team discipline (punctuality, observing bed times and curfews, attendance at meals, general team conduct), measured at baseline and after the experiment, were subjected to EFA.
Correlations between items were all reasonably high (all r's > \Sexpr{min(arousalMatrix)}), which suggested that one factor would be appropriate (see Table ee Table ~\ref{tab:arousalCorrTable}). The KMO index and Bartlett's test both suggested high sampling adequacy, (KMO =  \Sexpr{KMOarousalMatrix$MSA}, \chi^2(\Sexpr{bartlettArousal$df}, N = \Sexpr{arousalSampleSize}) = \Sexpr{bartlettArousal$chisq}, p = \Sexpr{bartlettArousal$p.value}).
One factor, labelled ``Team Discipline'' was imposed on the data, which explained \Sexpr{prVar.ArousalFA}\% of the overall variance (SS Loading = \Sexpr{SSLoadings.ArousalFA}).  Guttmans \lambda = \Sexpr{reliabilityArousal$total[,3]}  and  Cronbachs \alpha = \Sexpr{reliabilityArousal$total[,2]}  indicated that the data reduction was appropriate and reliable.

\subsubsection{Athlete Technical Competence (objective and subjective measures)}

<<dataReductionTechnicalCompetence, eval=TRUE, echo=FALSE>>=
  #TechnicalCompetenceVariablesSubset:
  tlcTechnicalCompetence <- subset(tlc, select = c(yearsTeam, trainingAge, teamStatus,
                                            athleteStatus, indAbilityTeammates_1, indAbilityChina_1, indAbilityInternational_1, teamAbilityChina_1))
  tlcTechnicalCompetence.pca <- princomp(na.omit(tlcTechnicalCompetence))
  summary(tlcTechnicalCompetence.pca)
  #plot(tlcTechnicalCompetence.pca)

  tlcTechnicalCompetence.fa <- factanal(~ yearsTeam + trainingAge  + teamStatus +
                                            athleteStatus + indAbilityTeammates_1 + indAbilityChina_1 + indAbilityInternational_1, 2, data = tlc, rotation = "promax", na.action = na.exclude, scores = "regression")  #<- this formula format allows preserving of NAs for later rebind to df

  #-----------------------------SS Loadings----------------------#
  SSLoadings.objectiveCompetenceFA <- round(sum(tlcTechnicalCompetence.fa$loadings[,1]^2),
                                                digits = 2)

  SSLoadings.subjectiveCompetenceFA <- round(sum(tlcTechnicalCompetence.fa$loadings[,2]^2),
                                                digits = 2)
  #------------------Proportion of Variance----------------------#
  prVar.technicalCompetenceFA <-  round((colSums(tlcTechnicalCompetence.fa$loadings*tlcTechnicalCompetence.fa$loadings)/dim(tlcTechnicalCompetence.fa$loadings)[1]*100), digits = 1)

  unclass(prVar.technicalCompetenceFA)
  prVar.technicalCompetenceFA <- data.frame(prVar.technicalCompetenceFA)
  prVar.objectiveCompetenceFA <- prVar.technicalCompetenceFA[1,1]
  prVar.subjectiveCompetenceFA <- prVar.technicalCompetenceFA[2,1]


  head(tlcTechnicalCompetence.fa$scores)
  tlc <- cbind(tlc, tlcTechnicalCompetence.fa$scores)
  names(tlc)[names(tlc) == "Factor1"] <- "objectiveCompetenceFactor"
  names(tlc)[names(tlc) == "Factor2"] <- "subjectiveCompetenceFactor"
  technicalCompetenceMatrix <- cor(tlcTechnicalCompetence, use = "complete")
  objectiveCompetenceMatrix <- cor(subset(tlcTechnicalCompetence, select = c(yearsTeam, trainingAge, teamStatus, athleteStatus)))
  subjectiveCompetenceMatrix <- cor(subset(tlcTechnicalCompetence, select = c(indAbilityTeammates_1, indAbilityChina_1, indAbilityInternational_1)))

  #---------suitability measures (KMO & Bartlett)----------------#
  library(psych)
  KMOtechnicalCompetenceMatrix <- KMO(technicalCompetenceMatrix)
  # KMOTechnicalCompetenceMatrix$MSA is the colum in which the overal KMO is stored
  bartlettTechnicalCompetence <- cortest.bartlett(technicalCompetenceMatrix, n = 116) # what is the sample size here?
  # ls(BartlettTechnicalCompetence)
  # BartlettTechnicalCompetence$chisq, BartlettTechnicalCompetence$df, BartlettTechnicalCompetence$p.value
  # sample size? length(unique(tlc$englishName)*2)
  technicalCompetenceSampleSize <- length(unique(tlc$englishName)) # values for each participant measured at one time points

  #----------reliability measures--------------------------------#
  # Cronbach's Alpha and Guttman's Lambda using psych::alpha()
  #Cronbach's Alpha is located reliabilityObject$total[,2]
  #Guttman's Lambda is located reliabilityObject$total[,3]
  reliabilityTechnicalCompetence <- psych::alpha(technicalCompetenceMatrix)
  cronAlphaTechnicalCompetence <- reliabilityTechnicalCompetence$total[,2]
  guttLambdaTechnicalCompetence <- reliabilityTechnicalCompetence$total[,3]
@
<<technicalCompetenceCor, echo=F,eval=T>>=
  # be sure to import the variable subset data frame, not the correlation matrix
  corstarsl(tlcTechnicalCompetence)
  print(xtable(corstarsl(tlcTechnicalCompetence), type="latex",
                      caption = "Correlations between measures of technical competence",
                      label = "tab:technicalCompetenceCorrTable"),
                      file = "technicalCompetenceCorrTable.tex")
  # label = tab:technicalCompetenceCorrTable
@

All eight items relevant to technical competence were analysed in a correlation matrix to assess relatedness (see Table ~\ref{tab:technicalCompetenceCorrTable}). All measures of objective competence were highly correlated all r's >= \Sexpr{min(objectiveCompetenceMatrix)}),  and among measures of subjective competence (all items except for the team competence measure correlated at $> \Sexpr{min(subjectiveCompetenceMatrix)})$) suggested that the data could be explained by two underlying factors. Team Ability Chinese Provinces was dropped from analysis due to low correlation with other competence variables, possibly because the item did not ask about an individual athlete’s competence (it referred instead to an athlete’s opinion of the competence of the team of which they were a member).

An EFA of technical competence variables revealed that items of interest loaded on two factors. Measures of objective competence (Years Team, Training Age, Team Status, Athlete Status) loaded on the first factor, which was labelled ``Objective Competence'' because the measures were all objective markers of an athlete's competence.
Objective Competence explained \Sexpr{prVar.objectiveCompetenceFA}\% of the total variance (\Sexpr{SSLoadings.objectiveCompetenceFA}). The remaining measures of subjective competence (Ability Teammates, Ability Chinese Pros, Ability International Pros) loaded on the remaining factor.  The second factor was labelled ``Subjective Competence'', due to the fact that all measures were the product of athlete self-report.  Subjective competence explained \Sexpr{prVar.objectiveCompetenceFA}\% of the variance (\Sexpr{SSLoadings.subjectiveCompetenceFA}).
$Guttmans \lambda = \Sexpr{reliabilityTechnicalCompetence$total[,3]}$ and $Cronbachs \alpha = \Sexpr{reliabilityTechnicalCompetence$total[,2]}$ indicated that the data reduction was appropriate and reliable.


\subsubsection{Team Discipline}
<<dataReductionTeamDiscipline, eval=T, echo=F>>=
  #TeamDisciplineVariablesSubset: exclude effectivenessInContact (not relvant)
  tlcTeamDiscipline <- subset(tlc, select = c(teamAttendanceMeals, teamCurfew, teamGeneralConduct, teamPunctuality))
  tlcTeamDiscipline.pca <- princomp(na.omit(tlcTeamDiscipline))
  summary(tlcTeamDiscipline.pca)
  #plot(tlcTeamDiscipline.pca)

  tlcTeamDiscipline.fa <- factanal(~ teamAttendanceMeals + teamCurfew + teamGeneralConduct +
                                        teamPunctuality, 1, data = tlc, rotation = "promax", na.action = na.exclude, scores = "regression")  #<- this formula format allows preserving of NAs for later rebind to df

  #-----------------------------SS Loadings----------------------#
  SSLoadings.teamDisciplineFA <- round(sum(tlcTeamDiscipline.fa$loadings[,1]^2), digits = 2)
  #------------------Proportion of Variance----------------------#
  prVar.teamDisciplineFA <-  round((colSums(tlcTeamDiscipline.fa$loadings*tlcTeamDiscipline.fa$loadings)/dim(tlcTeamDiscipline.fa$loadings)[1]*100), digits = 1)

  head(tlcTeamDiscipline.fa$scores)
  tlc <- cbind(tlc, tlcTeamDiscipline.fa$scores)
  names(tlc)[names(tlc) == "Factor1"] <- "teamDisciplineFactor"
  teamDisciplineMatrix <- cor(tlcTeamDiscipline, use = "complete")

  #---------suitability measures (KMO & Bartlett)----------------#
  library(psych)
  KMOteamDisciplineMatrix <- KMO(teamDisciplineMatrix)
  # KMOTeamDisciplineMatrix$MSA is the colum in which the overal KMO is stored
  bartlettTeamDiscipline <- cortest.bartlett(teamDisciplineMatrix, n = 116) # what is the sample size here?
  # ls(BartlettTeamDiscipline)
  # BartlettTeamDiscipline$chisq, BartlettTeamDiscipline$df, BartlettTeamDiscipline$p.value
  # sample size? length(unique(tlc$englishName)*2)
  teamDisciplineSampleSize <- length(unique(tlc$englishName))*2 # values for each participant measured attwo time points

  #----------reliability measures--------------------------------#
  # Cronbach's Alpha and Guttman's Lambda using psych::alpha()
  #Cronbach's Alpha is located reliabilityObject$total[,2]
  #Guttman's Lambda is located reliabilityObject$total[,3]
  reliabilityTeamDiscipline <- psych::alpha(teamDisciplineMatrix)
  cronAlphaTeamDiscipline <- reliabilityTeamDiscipline$total[,2]
  guttLambdaTeamDiscipline <- reliabilityTeamDiscipline$total[,3]
@
<<teamDisciplineCor, echo=F,eval=T>>=
  # be sure to import the variable subset data frame, not the correlation matrix
  corstarsl(tlcTeamDiscipline)
  print(xtable(corstarsl(tlcTeamDiscipline), type="latex",
                      caption = "Correlations between variables measuring team discipline",
                      label = "tab:teamDisciplineCorrTable"),
                      file = "teamDisciplineCorrTable.tex")
  # label = tab:teamDisciplineCorrTable
@

Items concerning team discipline (attendance at meals, team curfew, general team conduct, punctuality to team engagements), measured at baseline and after the experiment, were subjected to EFA.  Correlations between items were all reasonably high (all r's > \Sexpr{min(teamDisciplineMatrix)}), which suggested that one factor would be appropriate (see Table ee Table ~\ref{tab:teamDisciplineCorrTable}).
The KMO index and Bartlett's test both suggested high sampling adequacy,
(KMO
  = \Sexpr{KMOteamDisciplineMatrix$MSA}
  , \chi^2(\Sexpr{bartlettTeamDiscipline$df}
  , N = \Sexpr{teamDisciplineSampleSize})
  = \Sexpr{bartlettTeamDiscipline$chisq},
  p = \Sexpr{bartlettTeamDiscipline$p.value}).
One factor, labelled ``Team Discipline'' was imposed on the data, which explained \Sexpr{prVar.teamDisciplineFA} \% of the overall variance
(SS Loading
  = \Sexpr{SSLoadings.teamDisciplineFA}).
Guttmans
  \lambda = \Sexpr{reliabilityTeamDiscipline$total[,3]}
  and  Cronbachs
  \alpha = \Sexpr{reliabilityTeamDiscipline$total[,2]}
indicated that the data reduction was appropriate and reliable.

% \myparagraph{Fatigue} - fatigue is measured pre and post experiment, but mental and prpe are measured only post-experiment, so no need for EFA





%Appendix
%% This is a follow-up EFA with individual and group performance in one matrix.
%<<dataReductionPerformanceAll, eval=TRUE, echo=FALSE>>=
%min(competenceMatrix)

%# 2. jointActionSuccess and individualComponentPerformance:
%#PerformanceComponentsTogether:
%tlcPerformance <- subset(tlc, select = c(groupDefensiveLine, groupAttackingLine,        groupSupportPlay, groupOnfieldCommunication, indDefense, passingTechnique, supportPlay, decisionMaking, effectivenessInContact))

%tlcPerformance.fa <- factanal(~ groupDefensiveLine + groupAttackingLine + groupSupportPlay + groupOnfieldCommunication +
                              %indDefense + passingTechnique + supportPlay + %decisionMaking + effectivenessInContact, 2,
                                 %data = tlc, rotation = "promax", na.action = na.exclude, %scores = "regression")
%tlcPerformance.fa

%tlcPerformanceMatrix <- cor(tlcPerformance, use = "complete")
%KMO(tlcPerformanceMatrix)
%library(psych)
%cortest.bartlett(tlcPerformanceMatrix, n = 116) # what is the sample size here?
%psych::alpha(tlcPerformanceMatrix)
%@





RESULTS:

ICC:


\input{/Users/jacob1/Documents/2017/Research/DPhil/Dissertation/finalDocuments/jointActionSocialBonding/images/ICCTable.tex}

\input{/Users/jacob1/Documents/2017/Research/DPhil/Dissertation/finalDocuments/jointActionSocialBonding/images/outcomeAvgSdSession.tex}


ICC values for perceptions of group performance relative to prior expectations were very low for each grouping variables (all < .10), indicating that between-group variance in perceptions of group performance was minimal across categories of experiment session, sex, team, and experiment location (Beijing or Shandong).  ICC values for group click were also low, with the exception being the value for experimental session (ICC = .14).
ICC values for social bonding to the training group did show some evidence of moderate between-group variance.

  ## create a variable list which we want in table one
  listVars <- c("AverageOutcome", "StandardDeviation")

  ## define categorical variables
  catVars <- c("Session", "Team")


  ## Create overall table:
  table1 <- CreateTableOne(vars = listVars,
                         data = outcomeDf,
                         strata = "Session",
                         factorVars = catVars,
                         test = T
                         )
 ## create table which is printable
 table1_overall <- print(table1,
                             quote = FALSE,
                             noSpaces = FALSE,
                             printToggle = FALSE
                             )
 ##print table
  print(xtable(table1_overall, type="latex",
                         caption = "Mean and standard deviation of performance outcome according to experiment session",
                         label = "tab:outcomeAvgSdSession"),
                         file="outcomeAvgSdSession.tex")


%\myparagraph{Prediction 1.a: higher perceptions of Joint Action Success will correlate with higher feelings of team click with the training group}

%<<jASClickScatter, fig.cap='', results='hide'>>=

apatheme=theme_bw()+
  theme(panel.grid.major=element_blank(),
        panel.grid.minor=element_blank(),
        panel.border=element_blank(),
        axis.line=element_line(),
        text=element_text(family='Times'))

jASClickScatter <- ggplot(twc, aes(x=jointActionSuccessPost, y=groupClickPostFactor,
                            color=condition)) + geom_point(shape = 1) +
                            geom_smooth(method=lm, se=FALSE)   # Don't add shaded confidence region
jASClickScatter +
            ggtitle("Joint Action Success predicts Group Click") +
            theme(plot.title = element_text(hjust=0, size=12)) +
            xlab("Joing Action Success") +
            ylab("Group Click") +
            apatheme
@

<<indPerfClickScatter, fig.cap='', results='hide'>>=

indPerfClickScatter <- ggplot(twc, aes(x=indPerformancePost, y=groupClickPostFactor,
                            color=condition)) + geom_point(shape = 1) +
                            geom_smooth(method=lm, se=FALSE)   # Don't add shaded confidence region
indPerfClickScatter +
            ggtitle("Perceptions of Individual Performance predicts feelings of Group Click") +
            theme(plot.title = element_text(hjust=0, size=12)) +
            xlab("Individual Performance") +
            ylab("Group Click") +
            apatheme
@


Figure ~\ref{fig:jASClickScatter} shows a strong positive correlation between perceived joint action success and feelings of ``team click'' with the training group post-Experiment.



<<jASClickModel, echo=F,eval=T>>=

jASClick.intercept <- lmer(groupClickPostFactor ~ 1 + ( 1 |sessionName),
                            data = twc,
                            REML = F)
jASClick.main <- lmer(groupClickPostFactor ~ jointActionSuccessPost + ( 1 |sessionName),
                            data = twc,
                            REML = F)
#summary(jASClick.main)

jASClick.controls <- lmer(groupClickPostFactor ~ jointActionSuccessPost +
                            indPerformancePost + arousalFactorPost + fullOutcomeAvg +
                            subjectiveCompetenceFactor + objectiveCompetenceFactor +
                            ( jointActionSuccessPost |sessionName),
                            data = twc,
                            REML = F)

summary(jASClick.controls)

# control = lmerControl(optimizer = "optimx", calc.derivs = FALSE, optCtrl = list(method = "nlminb", starttests = FALSE, kkt = FALSE)
@

#ASSUMPTIONS:
<<jASClickAssumptionsHist, fig.cap='',echo=F,eval=T>>=
#1.historgram with density line
jASClickResid <- resid(jASClick.controls, type = "pearson")
hist(jASClickResid , freq = FALSE, main = "Residuals: \n M1.a Joint Action Success \n predicts Group Click", xlab = "Residuals")
lines(density(jASClickResid, na.rm = TRUE))
#dev.copy(pdf, "TE1aHist.pdf")
#dev.off()
#non-normality
shapiro.test(jASClickResid)
psych::describe(jASClickResid)
@

<<jASClickAssumptionsScatter, fig.cap='',echo=F,eval=T>>=
#2.scatterPlot
plot(jASClick.controls, main = "Residuals: \n M1.a Joint Action Success predicts \n Group Click")
#dev.copy(pdf, "MLM3bScatter.pdf")
#dev.off()
@

<<jASClickAssumptionsQQNorm, fig.cap='',echo=F,eval=T>>=
#3.qqNorm
qqnorm(residuals(jASClick.controls), main = "Norm QQ Plot: \n M1.a Joint Action Success \n predicts Group Click")
qqline(residuals(jASClick.controls))
#dev.copy(pdf, "MLM3bQQNorm.pdf")
#dev.off()
@

<<jASClickAssumptionsCooksD, fig.cap='',echo=F,eval=T>>=
#indluential cases
#cook's distances all < 1, so no cause for concern, (Field 2012: 271)
plot(cooks.distance(jASClick.controls), main = "Cook's Distance: \n M1.a Joint Action Success \n predicts Group Click", ylab = "cooks.distance")
#dev.copy(pdf, "MLM3bCooksD.pdf")
#dev.off()
@








\myparagraph{Prediction 3.a: Perceptions of higher Joint Action Success will predict higher levels of Social Bonding to the training group}


<<jASBondScatter, fig.cap=''>>=
jASBondScatter <- ggplot(twc, aes(x=jointActionSuccessPost, y=groupBondingFactorPost,
                            color=condition)) + geom_point(shape = 1) +
                            geom_smooth(method=lm, se=FALSE)
jASBondScatter +
            ggtitle("Perceptions of Joint Action Success \n predict feelings of Social Bonding to training group") +
            theme(plot.title = element_text(size=12)) +
            xlab("Joint Action Success") +
            ylab("Social Bonding") +
            apatheme
@

Figure ~\ref{fig:jASBondScatter} shows a strong positive relationship between Joint Action Success and Social Bonding to the training group, suggesting that athletes who perceived greater success in components of joint action also felt higher levels of social bonding to their co-actors in the training drill.


<<jASBondingModel, eval=T,echo=F>>=

jASBonding.intercept <- lmer(groupBondingFactorPost ~ 1 + ( 1 |sessionName),
                            data = twc,
                            REML = F)
jASBonding.main <- lmer(groupBondingFactorPost ~ jointActionSuccessPost +
                            (jointActionSuccessPost|sessionName),
                            data = twc,
                            control = lmerControl(optimizer = "optimx", calc.derivs = FALSE, optCtrl = list(method = "nlminb", starttests = FALSE, kkt = FALSE)),
                            REML = F)

summary(jASBonding.main)

jASBonding.controls <- lmer(groupBondingFactorPost ~ jointActionSuccessPost +
                            indPerformancePost + arousalFactorPost + fullOutcomeAvg +
                            subjectiveCompetenceFactor + objectiveCompetenceFactor +
                            (jointActionSuccessPost|sessionName),
                            control = lmerControl(optimizer = "optimx", calc.derivs = FALSE, optCtrl = list(method = "nlminb", starttests = FALSE, kkt = FALSE)),
                            data = twc,
                            REML = F)

summary(groupPerfExpClick.controls)

jASBonding.condition.controls <- lmer(groupBondingFactorPost ~
                            jointActionSuccessPost*condition +
                            indPerformancePost + arousalFactorPost + fullOutcomeAvg +
                            subjectiveCompetenceFactor + objectiveCompetenceFactor +
                            (jointActionSuccessPost|sessionName),
                            control = lmerControl(optimizer = "optimx", calc.derivs = FALSE, optCtrl = list(method = "nlminb", starttests = FALSE, kkt = FALSE)),
                            data = twc,
                            REML = F)

summary(jASBonding.condition.controls)
@



\myparagraph{Prediction 4.a: Feelings of group click will mediate a relationship between joint action success and social bonding to the group}


<<jASClickBondMediationModel, eval=T,echo=F>>=
#library(lme4)
#library(lmerTest)
## Direct relationship X->Y: fit model and show summary
summary(m1 <- lmer(groupBondingFactorPost ~ jointActionSuccessPost +
                            indPerformancePost + arousalFactorPost + fullOutcomeAvg +
                            subjectiveCompetenceFactor + objectiveCompetenceFactor +
                            (jointActionSuccessPost|sessionName),
                            control = lmerControl(optimizer = "optimx", calc.derivs = FALSE, optCtrl = list(method = "nlminb", starttests = FALSE, kkt = FALSE)),
                            data = twc,
                            REML = F))

## X->M fit model and show summary
summary(m2 <- lmer(groupClickPostFactor ~ jointActionSuccessPost +
                                          indPerformancePost + arousalFactorPost + fullOutcomeAvg +
                                          subjectiveCompetenceFactor + objectiveCompetenceFactor +
                                          (jointActionSuccessPost|sessionName),
                                          data = twc,
                                          REML = F))

#install.packages("optimx")
#library("optimx")
## M->Y fit model and show summary
summary(m3 <- lmer(groupBondingFactorPost ~ jointActionSuccessPost*groupClickPostFactor +
                                            arousalFactorPost + fullOutcomeAvg +
                                            subjectiveCompetenceFactor + objectiveCompetenceFactor + (1 + jointActionSuccessPost + groupClickPostFactor | sessionName),
                                            data = twc, REML = FALSE, control = lmerControl(optimizer = "optimx", calc.derivs = FALSE, optCtrl = list(method = "nlminb", starttests = FALSE, kkt = FALSE))))

library(mediation)
med.out <- mediate(m2, m3, treat = "jointActionSuccessPost", mediator = "groupClickPostFactor")
summary(med.out)


@


%In-text LMER main model report:
\betaest
  \Sexpr{coef(summary(groupPerfExpClick.controls))["groupPerformance_3Norm","Estimate"]}
\CIstart
  \Sexpr{groupPerfExpClick.controls.CIs["groupPerformance_3Norm", 1]}
,
  \Sexpr{groupPerfExpClick.controls.CIs["groupPerformance_3Norm", 2]}
\CIfinish
\SE
  \Sexpr{coef(summary(groupPerfExpClick.controls))["groupPerformance_3Norm","Std. Error"]}
,
t(
  \Sexpr{coef(summary(groupPerfExpClick.controls))["groupPerformance_3Norm","df"]}
  )
=
  \Sexpr{coef(summary(groupPerfExpClick.controls))["groupPerformance_3Norm","t value"]}
,
\pvalue
  \Sexpr{coef(summary(groupPerfExpClick.controls))["groupPerformance_3Norm","Pr(>|t|)"]}
,
\MR2
  \Sexpr{groupPerfExpClick.controls.R2[,5]}
,
\CR2
  \Sexpr{groupPerfExpClick.controls.R2[,6]}














Model:
#CIs
model.CIs <- confint.merMod(model, method = "Wald")
#R^2s:
model.R2 <- sem.model.fits(model)

%then in text:
\CIstart
  \Sexpr{model.CIs["X", 1]}
,
  \Sexpr{model.CIs["X", 2]}
\CIfinish


%then in text:
\MR2
  \Sexpr{model.R2[,5]}
,
\CR2
  \Sexpr{model.R2[,6]}



Assumptions:

%%Normality of residuals
modelResid.Wald <- shapiro.test(modelResid)
%then in text:
(
  \resdist
    \Sexpr{jASgroupPerfExpClickIntResid.Wald$statistic},
  \pvalue
    \Sexpr{jASgroupPerfExpClickIntResid.Wald$p.value}
),

%Cook's D
modelCooksD <- cooks.distance(model)
%then in text:
\cooksD
=
  \Sexpr{max(jASgroupPerfExpClickIntCooksD)}, see model assumptions in Appendix  ~\ref{fig:M1aAssumptions}


















MODEL ASSUMPTIONS:

%%Model 1
\begin{figure}[htbp]
    \includegraphics[scale =.4]{images/TEM1Hist.pdf}
    \includegraphics[scale =.4]{images/TEM1Scatter.pdf}
    \includegraphics[scale =.4]{images/TEM1QQNorm.pdf}
    \includegraphics[scale =.4]{images/TEM1CooksD.pdf}
    \caption{Model 1 Assumptions: Positive violation of group performance expectations predicts feelings of Team Click, moderated by condition}
    \label{fig:M1Assumptions}
\end{figure}

%%Model 1a
\begin{figure}[htbp]
    \includegraphics[scale =.4]{images/TEM1aHist.pdf}
    \includegraphics[scale =.4]{images/TEM1aScatter.pdf}
    \includegraphics[scale =.4]{images/TEM1aQQNorm.pdf}
    \includegraphics[scale =.4]{images/TEM1aCooksD.pdf}
    \caption{Model 1a Assumptions: The interaction between positive violation of group performance expectations and perceptions of joint action success predicts feelings of Team Click}
    \label{fig:M1aAssumptions}
\end{figure}


%%Model 2
\begin{figure}[htbp]
    \includegraphics[scale =.4]{images/TEM2Hist.pdf}
    \includegraphics[scale =.4]{images/TEM2Scatter.pdf}
    \includegraphics[scale =.4]{images/TEM2QQNorm.pdf}
    \includegraphics[scale =.4]{images/TEM2CooksD.pdf}
    \caption{Model 2 Assumptions: Feelings of Team Click predict feelings of Social Bonding}
    \label{fig:M2Assumptions}
\end{figure}


%%Model 3
\begin{figure}[htbp]
    \includegraphics[scale =.4]{images/TEM3Hist.pdf}
    \includegraphics[scale =.4]{images/TEM3Scatter.pdf}
    \includegraphics[scale =.4]{images/TEM3QQNorm.pdf}
    \includegraphics[scale =.4]{images/TEM3CooksD.pdf}
    \caption{Model 3 Assumptions: Positive violation of group performance expectations predicts feelings of Social Bonding, moderated by condition}
    \label{fig:M3Assumptions}
\end{figure}
